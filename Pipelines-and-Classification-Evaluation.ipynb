{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Pipelines and Evaluating Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Pipeline?\n",
    "\n",
    "Pipelines can keep our code neat and clean all the way from gathering & cleaning our data, to creating models & fine-tuning them!\n",
    "\n",
    "**Advantages**: \n",
    "- Reduces complexity\n",
    "- Convenient \n",
    "- Flexible \n",
    "- Can help prevent mistakes (like data leakage between train and test set) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easily integrate transformers and estimators, plus cross validation!\n",
    "\n",
    "<img src=\"images/grid_search_cross_validation.png\" alt=\"cross validation image from sklearn's documentation\" width=500>\n",
    "\n",
    "Why might CV be good in instances when we're doing things like searching for optimal hyperparameters...?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, plot_confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start with the Titanic dataset from earlier today. Target is to predict `Survived`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab, then explore data\n",
    "df = pd.read_csv('data/titanic.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring numeric cols\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring object cols\n",
    "df[[c for c in df.columns if df[c].dtype == 'object']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Understanding - Aka Model-less Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring target distribution\n",
    "df['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Survived'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate - any thoughts on our model-less understanding?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "Let's find out how hard our problem is, by throwing things at it and seeing what sticks!\n",
    "\n",
    "Biggest thing to think about - what types of columns need to be treated differently?\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First define our used columns\n",
    "# Let's not use ['PassengerId', 'Name', 'Ticket', 'Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our X and y\n",
    "\n",
    "X = None\n",
    "y = None\n",
    "\n",
    "# and train test split - to create our val holdout set!\n",
    "X_train, X_hold, y_train, y_hold = train_test_split(X, y, test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up lists for columns requiring different treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, setting up the preprocessing steps for each type of col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package those pieces together using ColumnTransformer\n",
    "preprocessor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just out of curiosity, let's see what this looks like \n",
    "X_tr_transformed = preprocessor.fit_transform(X_train)\n",
    "X_tr_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "\n",
    "\n",
    "# Now - cross_validate!\n",
    "output = None\n",
    "\n",
    "# Print our test scores to show average and a measure of variation\n",
    "print(f\"Average ROC-AUC: {output['test_score'].mean()} +/- {output['test_score'].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try With Adjusted Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time for a new pipeline!\n",
    "\n",
    "\n",
    "# Now - cross_validate!\n",
    "output = None\n",
    "\n",
    "# Test scores\n",
    "print(f\"Average ROC-AUC: {output['test_score'].mean()} +/- {output['test_score'].std()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate\n",
    "\n",
    "How does this perform on our holdout set?\n",
    "\n",
    "First off - what might we want to check to evaluate our model?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can use a pipeline we defined earlier, but need to fit it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do we want to check first?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More space to check more metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Might want to plot a few things to help us visualize our metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now - Let's Build an Evaluate Function for Classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use our evaluate function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Visualization\n",
    "\n",
    "Code originated from: https://stackoverflow.com/questions/45715018/scikit-learn-how-to-plot-probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bonus, for making it to the end of the notebook...\n",
    "train_target = pd.DataFrame(y_train) # Create a df with our actual train y values\n",
    "# Add the predicted probabilities for 1 as a column\n",
    "train_target['Predicted Probability'] = clf_bal.predict_proba(X_train)[:,1]\n",
    "\n",
    "# Plot the two\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.hist(train_target[train_target['Survived']==0]['Predicted Probability'], \n",
    "         bins=50, label='Negatives')\n",
    "plt.hist(train_target[train_target['Survived']==1]['Predicted Probability'], \n",
    "         bins=50, label='Positives', alpha=0.7, color='r')\n",
    "plt.xlabel('Probability of being Positive Class')\n",
    "plt.ylabel('Number of records in each bin')\n",
    "plt.legend()\n",
    "plt.tick_params(axis='both')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - What to do with too many options in categorical columns?\n",
    "\n",
    "Data we can use for this: https://www.kaggle.com/c/cat-in-the-dat-ii (this file is in this github repo, in the data folder)\n",
    "\n",
    "New library you can install with more encoding techniques: https://contrib.scikit-learn.org/category_encoders/\n",
    "\n",
    "- (these work within SKLearn pipelines, since they're written in the SKLearn style!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "Check out Aurélien Geron's notebook of an [end-to-end ml project](https://github.com/ageron/handson-ml2/blob/master/02_end_to_end_machine_learning_project.ipynb) on his GitHub repo based around his book [_Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems (2nd ed)_](https://www.oreilly.com/library/view/hands-on-machine-learning/9781491962282/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
